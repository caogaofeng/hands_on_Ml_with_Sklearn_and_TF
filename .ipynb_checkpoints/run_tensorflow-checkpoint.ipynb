{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\python35\\lib\\importlib\\_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "d:\\python35\\lib\\importlib\\_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n"
     ]
    }
   ],
   "source": [
    "#创造图谱，运行\n",
    "x = tf.Variable(3, name=\"x\")\n",
    "y = tf.Variable(4, name=\"y\")\n",
    "f = x*x*y +y +2\n",
    "\n",
    "#创建会话\n",
    "sess = tf.Session()\n",
    "#初始化变量\n",
    "sess.run(x.initializer)\n",
    "sess.run(y.initializer)\n",
    "result = sess.run(f)\n",
    "print(result)\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    x.initializer.run()\n",
    "    y.initializer.run()\n",
    "    result = f.eval()\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "sess = tf.InteractiveSession()\n",
    "init.run()\n",
    "result = f.eval()\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#创建的任何节点都会自动添加到默认图形中\n",
    "x1 = tf.Variable(1)\n",
    "x1.graph is tf.get_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-3.7185181e+01]\n",
      " [ 4.3633747e-01]\n",
      " [ 9.3952334e-03]\n",
      " [-1.0711310e-01]\n",
      " [ 6.4479220e-01]\n",
      " [-4.0338000e-06]\n",
      " [-3.7813708e-03]\n",
      " [-4.2348403e-01]\n",
      " [-4.3721911e-01]]\n"
     ]
    }
   ],
   "source": [
    "#tensorflow实现线性回归\n",
    "import numpy as np\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "#计算 正太方程\n",
    "housing = fetch_california_housing()\n",
    "m, n = housing.data.shape\n",
    "housing_data_plus_bias = np.c_[np.ones((m, 1)), housing.data]\n",
    "\n",
    "x = tf.constant(housing_data_plus_bias, dtype=tf.float32, name=\"x\")\n",
    "y = tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32, name=\"y\")\n",
    "\n",
    "#计算x矩阵的转置\n",
    "xt = tf.transpose(x)\n",
    "theta = tf.matmul(tf.matmul(tf.matrix_inverse(tf.matmul(xt, x)), xt), y)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    theta_value = theta.eval()\n",
    "print(theta_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-3.69419202e+01]\n",
      " [ 4.36693293e-01]\n",
      " [ 9.43577803e-03]\n",
      " [-1.07322041e-01]\n",
      " [ 6.45065694e-01]\n",
      " [-3.97638942e-06]\n",
      " [-3.78654265e-03]\n",
      " [-4.21314378e-01]\n",
      " [-4.34513755e-01]]\n"
     ]
    }
   ],
   "source": [
    "#numpy 计算正太方程\n",
    "\n",
    "x = housing_data_plus_bias\n",
    "y = housing.target.reshape(-1, 1)\n",
    "theta_numpy = np.linalg.inv(x.T.dot(x)).dot(x.T).dot(y)\n",
    "print(theta_numpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-3.69419202e+01]\n",
      " [ 4.36693293e-01]\n",
      " [ 9.43577803e-03]\n",
      " [-1.07322041e-01]\n",
      " [ 6.45065694e-01]\n",
      " [-3.97638942e-06]\n",
      " [-3.78654265e-03]\n",
      " [-4.21314378e-01]\n",
      " [-4.34513755e-01]]\n"
     ]
    }
   ],
   "source": [
    "#sklearn 计算\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(housing.data, housing.target.reshape(-1, 1))\n",
    "\n",
    "print(np.r_[lin_reg.intercept_.reshape(-1, 1), lin_reg.coef_.T])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.00000000e+00  6.60969987e-17  5.50808322e-18  6.60969987e-17\n",
      " -1.06030602e-16 -1.10161664e-17  3.44255201e-18 -1.07958431e-15\n",
      " -8.52651283e-15]\n",
      "[ 0.38915536  0.36424355  0.5116157  ... -0.06612179 -0.06360587\n",
      "  0.01359031]\n",
      "0.11111111111111005\n",
      "(20640, 9)\n"
     ]
    }
   ],
   "source": [
    "#实现梯度下降\n",
    "#当使用梯度下降时，请记住，首先要对输入特征向量进行归一化，否则训练可能要慢得多。\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaled_housing_data = scaler.fit_transform(housing.data)\n",
    "scaled_housing_data_plus_bias = np.c_[np.ones((m, 1)), scaled_housing_data]\n",
    "\n",
    "print(scaled_housing_data_plus_bias.mean(axis=0))\n",
    "print(scaled_housing_data_plus_bias.mean(axis=1))\n",
    "print(scaled_housing_data_plus_bias.mean())\n",
    "print(scaled_housing_data_plus_bias.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 MSE = 6.444157\n",
      "Epoch 100 MSE = 4.9585066\n",
      "Epoch 200 MSE = 4.8961806\n",
      "Epoch 300 MSE = 4.8700824\n",
      "Epoch 400 MSE = 4.852078\n",
      "Epoch 500 MSE = 4.8390403\n",
      "Epoch 600 MSE = 4.829542\n",
      "Epoch 700 MSE = 4.8226123\n",
      "Epoch 800 MSE = 4.8175488\n",
      "Epoch 900 MSE = 4.8138423\n"
     ]
    }
   ],
   "source": [
    "#手动计算梯度\n",
    "\n",
    "housing = fetch_california_housing()  \n",
    "m, n = housing.data.shape  \n",
    "m, n = housing.data.shape  \n",
    "#np.c_按colunm来组合array  \n",
    "housing_data_plus_bias = np.c_[np.ones((m, 1)), housing.data]  \n",
    "scaled_housing_data_plus_bias = scaler.fit_transform(housing_data_plus_bias)  \n",
    "n_epochs = 1000  \n",
    "learning_rate = 0.01  \n",
    "X = tf.constant(scaled_housing_data_plus_bias, dtype=tf.float32, name=\"X\")  \n",
    "y = tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32, name=\"y\")  \n",
    "theta = tf.Variable(tf.random_uniform([n + 1, 1], -1.0, 1.0), name=\"theta\")  \n",
    "y_pred = tf.matmul(X, theta, name=\"predictions\")  \n",
    "error = y_pred - y  \n",
    "mse = tf.reduce_mean(tf.square(error), name=\"mse\")  \n",
    "gradients = 2/m * tf.matmul(tf.transpose(X), error)  \n",
    "#tf.assign()方法是为第一个参数变量赋予第二个参数的值\n",
    "training_op = tf.assign(theta, theta - learning_rate * gradients)  \n",
    "init = tf.global_variables_initializer()  \n",
    "with tf.Session() as sess:  \n",
    "    sess.run(init)  \n",
    "    for epoch in range(n_epochs):  \n",
    "        if epoch % 100 == 0:  \n",
    "            print(\"Epoch\", epoch, \"MSE =\", mse.eval())  \n",
    "        sess.run(training_op)  \n",
    "    best_theta = theta.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.24286199],\n",
       "       [ 0.7362226 ],\n",
       "       [ 0.13232774],\n",
       "       [-0.03092434],\n",
       "       [ 0.08613039],\n",
       "       [ 0.00164858],\n",
       "       [-0.03848343],\n",
       "       [-0.8886295 ],\n",
       "       [-0.8456019 ]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TensorFlow 计算梯度\n",
    "grandients = tf.gradients(mse, [theta])[0]#计算mse相对于theta的梯度向量"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 mse= 6.4057884\n",
      "epoch 100 mse= 4.8769813\n",
      "epoch 200 mse= 4.847929\n",
      "epoch 300 mse= 4.836015\n",
      "epoch 400 mse= 4.827467\n",
      "epoch 500 mse= 4.821202\n",
      "epoch 600 mse= 4.816607\n",
      "epoch 700 mse= 4.8132224\n",
      "epoch 800 mse= 4.810727\n",
      "epoch 900 mse= 4.808878\n",
      "best theta:\n",
      "[[-0.3173988 ]\n",
      " [ 0.8415313 ]\n",
      " [ 0.14176564]\n",
      " [-0.24916515]\n",
      " [ 0.27507344]\n",
      " [ 0.00371449]\n",
      " [-0.04152706]\n",
      " [-0.7209345 ]\n",
      " [-0.6910958 ]]\n"
     ]
    }
   ],
   "source": [
    "#使用优化器\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "training_op = optimizer.minimize(mse)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        if epoch%100 == 0:\n",
    "            print(\"epoch\", epoch, \"mse=\",mse.eval())\n",
    "        sess.run(training_op)\n",
    "    best_theta = theta.eval()\n",
    "    \n",
    "print(\"best theta:\")\n",
    "print(best_theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best theta:\n",
      "[[ 0.9045429 ]\n",
      " [ 0.82961667]\n",
      " [ 0.11875106]\n",
      " [-0.26552206]\n",
      " [ 0.30569237]\n",
      " [-0.00450321]\n",
      " [-0.03932616]\n",
      " [-0.8998926 ]\n",
      " [-0.87054753]]\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "n_epochs = 1000\n",
    "learning = 0.01\n",
    "\n",
    "x = tf.constant(scaled_housing_data_plus_bias, dtype=tf.float32, name=\"x\")\n",
    "y = tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32, name=\"y\")\n",
    "\n",
    "theta = tf.Variable(tf.random_uniform([n+1, 1], -1.0, 1.0, seed=42), name=\"theta\")\n",
    "y_pred = tf.matmul(x, theta, name=\"predictions\")\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name=\"mse\")\n",
    "\n",
    "optimizer = tf.train.MomentumOptimizer(learning_rate=learning_rate, momentum=0.9)\n",
    "training_op = optimizer.minimize(mse)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        sess.run(training_op)\n",
    "        \n",
    "    best_theta = theta.eval()\n",
    "    \n",
    "print(\"best theta:\")\n",
    "print(best_theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6. 7. 8.]]\n",
      "[[ 9. 10. 11.]\n",
      " [12. 13. 14.]]\n"
     ]
    }
   ],
   "source": [
    "#Feeding data to the training algorithm\n",
    "#占位符（placeholder）节点\n",
    "#feed_dict传递给eval()方法并指定A的值\n",
    "\n",
    "A = tf.placeholder(tf.float32, shape=(None, 3))\n",
    "B = A + 5\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    B_val_1 = B.eval(feed_dict={A:[[1,2,3]]})\n",
    "    B_val_2 = B.eval(feed_dict={A:[[4,5,6],[7,8,9]]})\n",
    "    \n",
    "print(B_val_1)\n",
    "print(B_val_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 1000\n",
    "learning_rate = 0.01\n",
    "x = tf.placeholder(tf.float32, shape=(None, n+1), name=\"x\")\n",
    "y = tf.placeholder(tf.float32, shape=(None,  1), name=\"y\")\n",
    "theta = tf.Variable(tf.random_uniform([n + 1, 1], -1.0, 1.0, seed=42), name=\"theta\")\n",
    "y_pred = tf.matmul(x, theta, name=\"predictions\")\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name=\"mse\")\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "training_op = optimizer.minimize(mse)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "batch_size = 100\n",
    "n_batches = int(np.ceil(m/batch_size))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.9045429 ]\n",
      " [ 0.82172453]\n",
      " [ 0.11330824]\n",
      " [-0.21355605]\n",
      " [ 0.32225588]\n",
      " [-0.00730818]\n",
      " [ 0.00515022]\n",
      " [-0.88384354]\n",
      " [-0.85685915]]\n"
     ]
    }
   ],
   "source": [
    "def fetch_batch(epoch, batch_index, batch_size):\n",
    "    np.random.seed(epoch*n_batches + batch_index)\n",
    "    indices = np.random.randint(m, size=batch_size)\n",
    "    x_batch = scaled_housing_data_plus_bias[indices]\n",
    "    y_batch = housing.target.reshape(-1, 1)[indices]\n",
    "    return x_batch, y_batch\n",
    "\n",
    "n_epochs = 10\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(n_epochs):\n",
    "        for batch_index in range(n_batches):\n",
    "            x_batch, y_batch = fetch_batch(epoch, batch_index, batch_size)\n",
    "            sess.run(training_op, feed_dict={x:x_batch, y:y_batch})\n",
    "        best_theta = theta.eval()   \n",
    "        \n",
    "        \n",
    "        \n",
    "print(best_theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 MSE = 5.678427\n",
      "Epoch 100 MSE = 4.8873253\n",
      "Epoch 200 MSE = 4.8512945\n",
      "Epoch 300 MSE = 4.837425\n",
      "Epoch 400 MSE = 4.8280025\n",
      "Epoch 500 MSE = 4.821218\n",
      "Epoch 600 MSE = 4.8163137\n",
      "Epoch 700 MSE = 4.812756\n",
      "Epoch 800 MSE = 4.810175\n",
      "Epoch 900 MSE = 4.8083014\n"
     ]
    }
   ],
   "source": [
    "#保存模型\n",
    "\n",
    "n_epochs = 1000\n",
    "learning_rate = 0.01\n",
    "x = tf.constant(scaled_housing_data_plus_bias, dtype=tf.float32, name=\"x\")            # not shown\n",
    "y = tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32, name=\"y\") \n",
    "theta = tf.Variable(tf.random_uniform([n + 1, 1], -1.0, 1.0, seed=42), name=\"theta\")\n",
    "y_pred = tf.matmul(x, theta, name=\"predictions\")\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name=\"mse\")\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "training_op = optimizer.minimize(mse) \n",
    "init = tf.global_variables_initializer()\n",
    "#创建保存节点\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        if epoch % 100 == 0:\n",
    "            print(\"Epoch\", epoch, \"MSE =\", mse.eval())                                # not shown\n",
    "            save_path = saver.save(sess, \"/tmp/my_model.ckpt\")\n",
    "        sess.run(training_op)\n",
    "    \n",
    "    best_theta = theta.eval()\n",
    "    save_path = saver.save(sess, \"/tmp/my_model_final.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /tmp/my_model_final.ckpt\n"
     ]
    }
   ],
   "source": [
    "#恢复模型\n",
    "#执行阶段的开始，而不是使用init节点初始化变量，你可以调用restore()方法 的保存器对象\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, \"/tmp/my_model_final.ckpt\")\n",
    "    best_theta_restored = theta.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(best_theta, best_theta_restored)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#默认情况下，保存器将以自己的名称保存并还原所有变量，但如果需要更多控制，则可以指定要保存或还原的变量以及要使用的名称。\n",
    "#以下保存器将仅保存或恢复theta变量，它的键名称是weights\n",
    "\n",
    "saver = tf.train.Saver({\"weights\": theta})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#使用 TensorBoard 展现图形和训练曲线\n",
    "#您每次运行程序时都需要使用不同的日志目录，否则 TensorBoard 将会合并来自不同运行的统计信息，这将会混乱可视化。\n",
    "\n",
    "#最简单的解决方案是在日志目录名称中包含时间戳\n",
    "\n",
    "from datetime import datetime\n",
    "now = datetime.utcnow().strftime(\"%Y%m%d%H%M%S\")\n",
    "root_logdir = \"tf_logs\"\n",
    "logdir = \"{}/run-{}\".format(root_logdir,now)\n",
    "\n",
    "\n",
    "n_epochs = 1000\n",
    "learning_rate = 0.01\n",
    "\n",
    "x = tf.placeholder(tf.float32, shape=(None, n + 1), name=\"x\")\n",
    "y = tf.placeholder(tf.float32, shape=(None, 1), name=\"y\")\n",
    "theta = tf.Variable(tf.random_uniform([n + 1, 1], -1.0, 1.0, seed=42), name=\"theta\")\n",
    "y_pred = tf.matmul(x, theta, name=\"predictions\")\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name=\"mse\")\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "training_op = optimizer.minimize(mse)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "#创建一个节点，求mse值，并将其写入TensorBoar兼容的二进制日志字符串（称为摘要）中\n",
    "mse_summary = tf.summary.scalar(\"mse\", mse)\n",
    "#创建一个FileWriter，将摘要写入日志目录中的日志文件中\n",
    "file_writer = tf.summary.FileWriter(logdir, tf.get_default_graph())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 10\n",
    "batch_size = 100\n",
    "n_batches = int(np.ceil(m / batch_size))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        for batch_index in range(n_batches):\n",
    "            x_batch, y_batch = fetch_batch(epoch, batch_index, batch_size)\n",
    "            #每10个小批量，输出mse_summary节点，\n",
    "            if batch_index % 10 == 0:\n",
    "                summary_str = mse_summary.eval(feed_dict={x:x_batch, y:y_batch})\n",
    "                step = epoch * n_batches + batch_index\n",
    "                file_writer.add_summary(summary_str, step)\n",
    "            sess.run(training_op, feed_dict={x:x_batch, y:y_batch})\n",
    "        best_theta = theta.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.9045429 ],\n",
       "       [ 0.82172453],\n",
       "       [ 0.11330824],\n",
       "       [-0.21355605],\n",
       "       [ 0.32225588],\n",
       "       [-0.00730818],\n",
       "       [ 0.00515022],\n",
       "       [-0.88384354],\n",
       "       [-0.85685915]], dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_writer.close()\n",
    "best_theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据集:20640行,8列\n",
      "[[ 2.070016  ]\n",
      " [ 0.8204561 ]\n",
      " [ 0.1173173 ]\n",
      " [-0.22739051]\n",
      " [ 0.3113402 ]\n",
      " [ 0.00353193]\n",
      " [-0.01126994]\n",
      " [-0.91643935]\n",
      " [-0.8795008 ]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "m, n = housing.data.shape\n",
    "print(\"数据集:{}行,{}列\".format(m,n))\n",
    "housing_data_plus_bias = np.c_[np.ones((m, 1)), housing.data]\n",
    "scaler = StandardScaler()\n",
    "scaled_housing_data = scaler.fit_transform(housing.data)\n",
    "scaled_housing_data_plus_bias = np.c_[np.ones((m, 1)), scaled_housing_data]\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "now = datetime.utcnow().strftime(\"%Y%m%d%H%M%S\")\n",
    "root_logdir = r\"D://tf_logs\"\n",
    "logdir = \"{}/run-{}/\".format(root_logdir, now)\n",
    "n_epochs = 1000\n",
    "learning_rate = 0.01\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n + 1), name=\"X\")\n",
    "y = tf.placeholder(tf.float32, shape=(None, 1), name=\"y\")\n",
    "theta = tf.Variable(tf.random_uniform([n + 1, 1], -1.0, 1.0, seed=42), name=\"theta\")\n",
    "y_pred = tf.matmul(X, theta, name=\"predictions\")\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name=\"mse\")\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "training_op = optimizer.minimize(mse)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "mse_summary = tf.summary.scalar('MSE', mse)\n",
    "file_writer = tf.summary.FileWriter(logdir, tf.get_default_graph())\n",
    "\n",
    "n_epochs = 10\n",
    "batch_size = 100\n",
    "n_batches = int(np.ceil(m / batch_size))\n",
    "\n",
    "def fetch_batch(epoch, batch_index, batch_size):\n",
    "    np.random.seed(epoch * n_batches + batch_index)  # not shown in the book\n",
    "    indices = np.random.randint(m, size=batch_size)  # not shown\n",
    "    X_batch = scaled_housing_data_plus_bias[indices] # not shown\n",
    "    y_batch = housing.target.reshape(-1, 1)[indices] # not shown\n",
    "    return X_batch, y_batch\n",
    "\n",
    "with tf.Session() as sess:                                                        # not shown in the book\n",
    "    sess.run(init)                                                                # not shown\n",
    "\n",
    "    for epoch in range(n_epochs):                                                 # not shown\n",
    "        for batch_index in range(n_batches):\n",
    "            X_batch, y_batch = fetch_batch(epoch, batch_index, batch_size)\n",
    "            if batch_index % 10 == 0:\n",
    "                summary_str = mse_summary.eval(feed_dict={X: X_batch, y: y_batch})\n",
    "                step = epoch * n_batches + batch_index\n",
    "                file_writer.add_summary(summary_str, step)\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "\n",
    "    best_theta = theta.eval()\n",
    "file_writer.close()\n",
    "print(best_theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#名称作用域"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
